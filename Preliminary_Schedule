<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Abstracts and Program</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 40px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 32px; padding-right: 32px; padding-bottom: 0px; break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none 0s ease 0s; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
svg[id^="mermaidChart"] { line-height: 1em; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
mark .md-meta { color: rgb(0, 0, 0); opacity: 0.3 !important; }


html {
	font-size: 19px;
}

html, body {
	margin: auto;
	background: #fefefe;
}
body {
	font-family: "Vollkorn", Palatino, Times;
	color: #333;
	line-height: 1.4;
	text-align: justify;
}

#write {
	max-width: 960px;
	margin: 0 auto;
	margin-bottom: 2em;
	line-height: 1.53;
	padding-top: 40px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1100px;
	}
}

/* Typography
-------------------------------------------------------- */

#write>h1:first-child,
h1 {
	margin-top: 1.6em;
	font-weight: normal;
}

h1 {
	font-size:3em;
}

h2 {
	margin-top:2em;
	font-weight: normal;
}

h3 {
	font-weight: normal;
	font-style: italic;
	margin-top: 3em;
}

h1, 
h2, 
h3{
	text-align: center;
}

h2:after{
	border-bottom: 1px solid #2f2f2f;
    content: '';
    width: 100px;
    display: block;
    margin: 0 auto;
    height: 1px;
}

h1+h2, h2+h3 {
	margin-top: 0.83em;
}

p,
.mathjax-block {
	margin-top: 0;
	-webkit-hypens: auto;
	-moz-hypens: auto;
	hyphens: auto;
}
ul {
	list-style: square;
	padding-left: 1.2em;
}
ol {
	padding-left: 1.2em;
}
blockquote {
	margin-left: 1em;
	padding-left: 1em;
	border-left: 1px solid #ddd;
}
code,
pre {
	font-family: "Consolas", "Menlo", "Monaco", monospace, serif;
	font-size: .9em;
	background: white;
}
.md-fences{
	margin-left: 1em;
	padding-left: 1em;
	border: 1px solid #ddd;
	padding-bottom: 8px;
	padding-top: 6px;
	margin-bottom: 1.5em;
}

a {
	color: #2484c1;
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a img {
	border: none;
}
h1 a,
h1 a:hover {
	color: #333;
	text-decoration: none;
}
hr {
	color: #ddd;
	height: 1px;
	margin: 2em 0;
	border-top: solid 1px #ddd;
	border-bottom: none;
	border-left: 0;
	border-right: 0;
}
.ty-table-edit {
	background: #ededed;
    padding-top: 4px;
}
table {
	margin-bottom: 1.333333rem
}
table th,
table td {
	padding: 8px;
	line-height: 1.333333rem;
	vertical-align: top;
	border-top: 1px solid #ddd
}
table th {
	font-weight: bold
}
table thead th {
	vertical-align: bottom
}
table caption+thead tr:first-child th,
table caption+thead tr:first-child td,
table colgroup+thead tr:first-child th,
table colgroup+thead tr:first-child td,
table thead:first-child tr:first-child th,
table thead:first-child tr:first-child td {
	border-top: 0
}
table tbody+tbody {
	border-top: 2px solid #ddd
}

.task-list{
	padding:0;
}

.md-task-list-item {
	padding-left: 1.6rem;
}

.md-task-list-item > input:before {
	content: '\221A';
	display: inline-block;
	width: 1.33333333rem;
  	height: 1.6rem;
	vertical-align: middle;
	text-align: center;
	color: #ddd;
	background-color: #fefefe;
}

.md-task-list-item > input:checked:before,
.md-task-list-item > input[checked]:before{
	color: inherit;
}
.md-tag {
	color: inherit;
	font: inherit;
}
#write pre.md-meta-block {
	min-height: 35px;
	padding: 0.5em 1em;
}
#write pre.md-meta-block {
	white-space: pre;
	background: #f8f8f8;
	border: 0px;
	color: #999;
	
	width: 100vw;
	max-width: calc(100% + 60px);
	margin-left: -30px;
	border-left: 30px #f8f8f8 solid;
	border-right: 30px #f8f8f8 solid;

	margin-bottom: 2em;
	margin-top: -1.3333333333333rem;
	padding-top: 26px;
	padding-bottom: 10px;
	line-height: 1.8em;
	font-size: 0.9em;
	font-size: 0.76em;
	padding-left: 0;
}
.md-img-error.md-image>.md-meta{
	vertical-align: bottom;
}
#write>h5.md-focus:before {
	top: 2px;
}

.md-toc {
	margin-top: 40px;
}

.md-toc-content {
	padding-bottom: 20px;
}

.outline-expander:before {
	color: inherit;
	font-size: 14px;
	top: auto;
	content: "\f0da";
	font-family: FontAwesome;
}

.outline-expander:hover:before,
.outline-item-open>.outline-item>.outline-expander:before {
  	content: "\f0d7";
}

/** source code mode */
#typora-source {
	font-family: Courier, monospace;
    color: #6A6A6A;
}

.html-for-mac #typora-sidebar {
    -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, .175);
    box-shadow: 0 6px 12px rgba(0, 0, 0, .175);
}

.cm-s-typora-default .cm-header, 
.cm-s-typora-default .cm-property,
.CodeMirror.cm-s-typora-default div.CodeMirror-cursor {
	color: #428bca;
}

.cm-s-typora-default .cm-atom, .cm-s-typora-default .cm-number {
	color: #777777;
}

.typora-node .file-list-item-parent-loc, 
.typora-node .file-list-item-time, 
.typora-node .file-list-item-summary {
	font-family: arial, sans-serif;
}

.md-task-list-item>input {
    margin-left: -1.3em;
    margin-top: calc(1rem - 12px);
}

.md-mathjax-midline {
	background: #fafafa;
}

.md-fences .code-tooltip {
	bottom: -2em !important;
}

.dropdown-menu .divider {
	border-color: #e5e5e5;
}


</style>
</head>
<body class='typora-export os-windows' >
<div  id='write'  class = ''><p>&nbsp;</p><h1><a name="preliminary-schedule-sysmus20" class="md-header-anchor"></a><span>Preliminary Schedule SysMus20</span></h1><p><span>																		</span><span>all times in BST (UTC+1)</span></p><hr /><h6><a name="" class="md-header-anchor"></a></h6><p><strong><em><span>Table of Contents</span></em></strong><span> </span></p><p><span>For times and abstracts, please click, on the links below (you might have to save the file as pdf first) or scroll further down.</span></p><hr /><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n1189"><a class="md-toc-inner" href="#preliminary-schedule-sysmus20">Preliminary Schedule SysMus20</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1202"><a class="md-toc-inner" href="#"></a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n1188"><a class="md-toc-inner" href="#tuesday-september-15th">Tuesday, September 15th</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1117"><a class="md-toc-inner" href="#opening-remarks">Opening Remarks</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1997"><a class="md-toc-inner" href="#-n1997"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n161"><a class="md-toc-inner" href="#keynote">Keynote </a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1999"><a class="md-toc-inner" href="#-n1999"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n128"><a class="md-toc-inner" href="#paper-session-1">Paper Session 1</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1132"><a class="md-toc-inner" href="#communication-and-meaning">Communication and Meaning</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1737"><a class="md-toc-inner" href="#-n1737"></a></span><span role="listitem" class="md-toc-item md-toc-h5" data-ref="n830"><a class="md-toc-inner" href="#communication-of-musical-meaning-from-text-through-improvisation-to-the-listener-helena-dukic-richard-parncutt">Communication of musical meaning from text, through improvisation to the listener (<em>Helena Dukic, Richard Parncutt</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n812"><a class="md-toc-inner" href="#-n812"></a></span><span role="listitem" class="md-toc-item md-toc-h5" data-ref="n811"><a class="md-toc-inner" href="#musical-pragmatics-an-interdisciplinary-approach-to-musical-meaning-patricia-dreesbach">Musical Pragmatics: An Interdisciplinary Approach to Musical Meaning (<em>Patricia Dreesbach</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1742"><a class="md-toc-inner" href="#-n1742"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n8"><a class="md-toc-inner" href="#paper-session-2">Paper Session 2</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1131"><a class="md-toc-inner" href="#computational-modelling-and-audio-processing"> Computational Modelling and Audio Processing</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n9"><a class="md-toc-inner" href="#-n9"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n814"><a class="md-toc-inner" href="#effect-of-musical-training-in-preserving-the-temporal-and-spatial-hearing-processing-abilities-in-elderly-adults-sreeraj-konadath-ranjini-dorai-k-v-nisha">Effect of musical training in preserving the temporal and spatial hearing processing abilities in elderly adults (<em>Sreeraj Konadath, Ranjini Dorai, K. V. Nisha</em>) </a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n11"><a class="md-toc-inner" href="#-n11"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n815"><a class="md-toc-inner" href="#modelling-large-scale-thematic-structure-in-music-edward-hall-marcus-pearce">Modelling Large-Scale Thematic Structure in Music (<em>Edward Hall, Marcus Pearce</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n14"><a class="md-toc-inner" href="#-n14"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n816"><a class="md-toc-inner" href="#analysis-of-lip-flow-in-trumpet-playing-using-iterative-adaptive-inverse-filtering-gustavo-machado-oliveira-davi-mota-maurício-loureiro">Analysis of lip flow in trumpet playing using iterative adaptive inverse filtering (<em>Gustavo Machado Oliveira, Davi Mota, Maurício Loureiro</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1751"><a class="md-toc-inner" href="#-n1751"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n165"><a class="md-toc-inner" href="#poster-session-1">Poster Session 1</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n170"><a class="md-toc-inner" href="#-n170"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1750"><a class="md-toc-inner" href="#paralysis-by-analysis-effects-of-focus-of-attention-on-acoustic-and-motion-parameters-in-open-string-violin-bowing-emma-allingham--clemens-wöllner">“Paralysis by analysis”: Effects of focus of attention on acoustic and motion parameters in open string violin bowing (<em>Emma Allingham,  Clemens Wöllner</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n605"><a class="md-toc-inner" href="#-n605"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n184"><a class="md-toc-inner" href="#a-case-study-on-music-education-in-19th-century-giardini-dinfanzia-giovanna-carugno">A Case Study on Music Education in 19th Century Giardini d’Infanzia (<em>Giovanna Carugno</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n607"><a class="md-toc-inner" href="#-n607"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n195"><a class="md-toc-inner" href="#an-exploration-of-the-musical-or-sonic-properties-of-language---from-auditory-perception-to-interpretation-of-meaning-celia-denore-lopez">An exploration of the musical (or sonic) properties of language - from auditory perception to interpretation of meaning (<em>Celia Denore Lopez</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n610"><a class="md-toc-inner" href="#-n610"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n198"><a class="md-toc-inner" href="#personality-traits-and-reasons-of-daily-music-listening-are-associated-with-the-experience-of-groove-deniz-duman-petri-toiviainen-geoff-luck">Personality Traits and Reasons of Daily Music Listening are Associated with the Experience of Groove (<em>Deniz Duman, Petri Toiviainen, Geoff Luck</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n613"><a class="md-toc-inner" href="#-n613"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n201"><a class="md-toc-inner" href="#message-and-medium-in-musical-performance--intersemiotics-aspects-of-the-music-representation-marina-cesar">Message and medium in musical performance : intersemiotics aspects of the music representation (<em>Marina Cesar</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n817"><a class="md-toc-inner" href="#-n817"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n204"><a class="md-toc-inner" href="#the-size-of-musical-awe-correlations-of-musical-features-and-the-perceptions-of-virtual-size-landon-peck">The size of musical awe: Correlations of musical features and the perceptions of virtual size (<em>Landon Peck</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n616"><a class="md-toc-inner" href="#-n616"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n207"><a class="md-toc-inner" href="#inaudible-frequencies-in-the-context-of-scientific-studies-with-music-claudia-stirnat">Inaudible Frequencies in the Context of Scientific Studies with Music (<em>Claudia Stirnat</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n620"><a class="md-toc-inner" href="#-n620"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n210"><a class="md-toc-inner" href="#the-computer-notation-musica-anna-terzaroli">The computer notation: MUSICA (<em>Anna Terzaroli</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n622"><a class="md-toc-inner" href="#-n622"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n213"><a class="md-toc-inner" href="#evaluation-system-for-ai-based-music-generation-models-zongyu-yin-federico-reuben-tom-collins">Evaluation System for AI-based Music Generation Models (<em>Zongyu Yin, Federico Reuben, Tom Collins</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1753"><a class="md-toc-inner" href="#-n1753"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n17"><a class="md-toc-inner" href="#paper-session-3">Paper Session 3 </a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1130"><a class="md-toc-inner" href="#pandemicusicology---musical-behaviour-in-times-of-covid-19">Pandem(ic)usicology - Musical Behaviour in Times of Covid-19</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n18"><a class="md-toc-inner" href="#-n18"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n862"><a class="md-toc-inner" href="#virtually-together-concerts-during-the-coronavirus-dana-swarbrick">Virtually Together: Concerts during the Coronavirus (<em>Dana Swarbrick</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n20"><a class="md-toc-inner" href="#-n20"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n864"><a class="md-toc-inner" href="#listening-niches-on-spotify-before-and-during-the-covid-19-pandemic-emily-hurwitz-carol-krumhansl">Listening Niches on Spotify Before and During the COVID-19 Pandemic (<em>Emily Hurwitz, Carol Krumhansl</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1762"><a class="md-toc-inner" href="#-n1762"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n866"><a class="md-toc-inner" href="#lunch-and-dinner-across-time-zones">Lunch and Dinner across Time zones</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1764"><a class="md-toc-inner" href="#-n1764"></a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n23"><a class="md-toc-inner" href="#wednesday-september-16th">Wednesday, September 16th</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n898"><a class="md-toc-inner" href="#-n898"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n891"><a class="md-toc-inner" href="#breakfast-and-dinner-across-time-zones">Breakfast and Dinner across Time zones</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1768"><a class="md-toc-inner" href="#-n1768"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n895"><a class="md-toc-inner" href="#breakfast--lunch--dinner-across-time-zones">Breakfast / Lunch / Dinner across Time zones</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1770"><a class="md-toc-inner" href="#-n1770"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n24"><a class="md-toc-inner" href="#paper-session-4">Paper Session 4</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1150"><a class="md-toc-inner" href="#music-across-cultures">Music Across Cultures</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1151"><a class="md-toc-inner" href="#-n1151"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n874"><a class="md-toc-inner" href="#invention-of-jīva-jeya-nātam-innovative-musicology-and-democratization-of-music-in-post-war-sri-lanka-pathmanesan-sanmugeswaran">Invention of Jīva Jeya Nātam: Innovative Musicology and Democratization of Music in Post-war Sri Lanka (<em>Pathmanesan Sanmugeswaran</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n638"><a class="md-toc-inner" href="#-n638"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n907"><a class="md-toc-inner" href="#chinese-whispers-choral-singing-in-a-second-language-eloise-mccann">Chinese Whispers: Choral Singing in a Second Language (<em>Eloise McCann</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n636"><a class="md-toc-inner" href="#-n636"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n908"><a class="md-toc-inner" href="#same-but-different---cross-cultural-comparison-of-ioi-pattern-distribution-in-rhythm-reproduction-of-school-children-gesine-wermke">Same but different? - Cross-cultural Comparison of IOI pattern distribution in Rhythm Reproduction of School-Children (<em>Gesine Wermke</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1775"><a class="md-toc-inner" href="#-n1775"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n56"><a class="md-toc-inner" href="#paper-session-5">Paper Session 5</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1155"><a class="md-toc-inner" href="#the-effect-of-musical-features-on-altered-states-of-consciousness">The effect of musical features on altered states of consciousness</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n59"><a class="md-toc-inner" href="#-n59"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n914"><a class="md-toc-inner" href="#assessing-properties-of-music-for-sleep--and-relaxation-rory-kirk-tim-metcalfe-maan-van-de-werken-renee-timmers">Assessing properties of music for sleep  and relaxation (<em>Rory Kirk, Tim Metcalfe, Maan van de Werken, Renee Timmers</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n916"><a class="md-toc-inner" href="#-n916"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n919"><a class="md-toc-inner" href="#ceremonial-and-recreational-use-of-music-supporting-psychedelic-trips-a-large-scale-musical-feature-study-christine-ahrends-ole-heggli-jan-stupacher-orla-mallon-lasse-damgaard-morten-kringelbach-peter-vuust">Ceremonial and recreational use of music supporting psychedelic trips: a large-scale musical feature study (<em>Christine Ahrends, Ole Heggli, Jan Stupacher, Orla Mallon, Lasse Damgaard, Morten Kringelbach, Peter Vuust</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1781"><a class="md-toc-inner" href="#-n1781"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n32"><a class="md-toc-inner" href="#paper-session-6">Paper Session 6</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1163"><a class="md-toc-inner" href="#music-and-memory">Music and Memory</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n33"><a class="md-toc-inner" href="#-n33"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n928"><a class="md-toc-inner" href="#models-of-memory-for-music-too-many-theories-or-not-enough-ana-marta-pacheco-aguiar">Models of Memory for Music: Too Many Theories or Not Enough? (<em>Ana Marta Pacheco Aguiar</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n634"><a class="md-toc-inner" href="#-n634"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n930"><a class="md-toc-inner" href="#music-evoked-autobiographical-memory-retrieval-in-healthy-populations-future-directions-for-a-unified-research-methods-approach-tara-henechowicz-michael-thaut">Music-Evoked Autobiographical Memory Retrieval in Healthy Populations: Future directions for a Unified Research Methods Approach (<em>Tara Henechowicz, Michael Thaut</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1786"><a class="md-toc-inner" href="#-n1786"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1058"><a class="md-toc-inner" href="#lunch-and-dinner-across-time-zones-n1058">Lunch and Dinner across Time zones</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1788"><a class="md-toc-inner" href="#-n1788"></a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n37"><a class="md-toc-inner" href="#thursday-september-17th">Thursday, September 17th</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1049"><a class="md-toc-inner" href="#-n1049"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1042"><a class="md-toc-inner" href="#breakfast-and-dinner-across-time-zones-n1042">Breakfast and Dinner across Time zones</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1045"><a class="md-toc-inner" href="#-n1045"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1046"><a class="md-toc-inner" href="#breakfast--lunch--dinner-across-time-zones-n1046">Breakfast / Lunch / Dinner across Time zones</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1794"><a class="md-toc-inner" href="#-n1794"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1040"><a class="md-toc-inner" href="#poster-session-2">Poster Session 2</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n316"><a class="md-toc-inner" href="#-n316"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1796"><a class="md-toc-inner" href="#revisiting-the-general-chord-type-gct-representation-a-novel-refined-algorithm-konstantinos-giannos-emilios-cambouropoulos">Revisiting the General Chord Type (GCT) representation: a novel refined algorithm (<em>Konstantinos Giannos, Emilios Cambouropoulos</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n944"><a class="md-toc-inner" href="#-n944"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n319"><a class="md-toc-inner" href="#digital-habitats-for-interdisciplinary-music-research-sebastian-klaßmann-nils-dahmen">Digital habitats for interdisciplinary music research (<em>Sebastian Klaßmann, Nils Dahmen</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n949"><a class="md-toc-inner" href="#-n949"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n314"><a class="md-toc-inner" href="#mimesis-and-kinaesthesia-in-music----a-behavioural-studyanna-kolesnikov-joshua--bamford-eduardo-andrade">Mimesis and kinaesthesia in music – a behavioural study(<em>Anna Kolesnikov, Joshua  Bamford, Eduardo Andrade</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n951"><a class="md-toc-inner" href="#-n951"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n321"><a class="md-toc-inner" href="#avatar-dance-off-what-makes-a-group-to-appear-bonded-and-powerful-harin-lee">Avatar dance off: What makes a group to appear bonded and powerful? (<em>Harin Lee</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n958"><a class="md-toc-inner" href="#-n958"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n302"><a class="md-toc-inner" href="#future-directions-in-music-and-emotion-studies-adopting-a-goal-directed-dimensional-appraisal-account-of-musical-emotions-thomas-lennie">Future directions in music and emotion studies: adopting a goal-directed dimensional-appraisal account of musical emotions (<em>Thomas Lennie</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n971"><a class="md-toc-inner" href="#-n971"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n324"><a class="md-toc-inner" href="#reflections-on-chinese-and-british-graded-piano-examination-systems----shcm-and-abrsm-as-case-studies-楚然-罗-churan-luo">Reflections on Chinese and British Graded Piano Examination Systems – SHCM and ABRSM as Case Studies (<em>楚然 罗 (Churan Luo)</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n974"><a class="md-toc-inner" href="#-n974"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n305"><a class="md-toc-inner" href="#the-emotive-and-neurological-response-to-break-routines-in-different-music-genres-amelia-s-turrell-amir-homayoun-javadi--andrea-halpern">The Emotive and Neurological Response to Break Routines in Different Music Genres (<em>Amelia S Turrell, Amir-Homayoun Javadi,  Andrea Halpern</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n979"><a class="md-toc-inner" href="#-n979"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n308"><a class="md-toc-inner" href="#an-investigation-into-the-relationship-between-musical-imagery-and-anxiety-michelle-ulor-freya-bailes-daryl-oconnor">An Investigation into the Relationship Between Musical Imagery and Anxiety (<em>Michelle Ulor, Freya Bailes, Daryl O'Connor</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n985"><a class="md-toc-inner" href="#-n985"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n299"><a class="md-toc-inner" href="#singers-are-affected-by-the-presence-of-their-own-performances-when-evaluating-their-peers-xinyue-wang-pauline-larrouy-maestri">Singers are affected by the presence of their own performances when evaluating their peers (<em>Xinyue Wang, Pauline Larrouy-Maestri</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1797"><a class="md-toc-inner" href="#-n1797"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n297"><a class="md-toc-inner" href="#paper-session-7">Paper Session 7</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1182"><a class="md-toc-inner" href="#music-and-well-being"> Music and Well-Being</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1176"><a class="md-toc-inner" href="#-n1176"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n990"><a class="md-toc-inner" href="#psychological-mechanisms-of-participation-in-inclusive-music-projects-experiences-of-marginalised-young-people-maruša-levstek-robin-banerjee">Psychological mechanisms of participation in inclusive music projects: Experiences of marginalised young people (<em>Maruša Levstek, Robin Banerjee</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n999"><a class="md-toc-inner" href="#-n999"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n994"><a class="md-toc-inner" href="#music-listening-as-a-coping-resource-in-domestic-and-international-university-students-dianna-vidas">Music Listening as a Coping Resource in Domestic and International University Students (<em>Dianna Vidas</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1802"><a class="md-toc-inner" href="#-n1802"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n2007"><a class="md-toc-inner" href="#keynote-n2007">Keynote </a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n2012"><a class="md-toc-inner" href="#-n2012"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n45"><a class="md-toc-inner" href="#paper-session-8">Paper Session 8</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1184"><a class="md-toc-inner" href="#audience-and-performance">Audience and Performance</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n46"><a class="md-toc-inner" href="#-n46"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1002"><a class="md-toc-inner" href="#empathic-listeners-identify-musically-expressed-emotion-more-accurately-in-improvised-jazz-omer-leshem-michael-schober">Empathic Listeners Identify Musically Expressed Emotion More Accurately in Improvised Jazz (<em>Omer Leshem, Michael Schober</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1008"><a class="md-toc-inner" href="#-n1008"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1010"><a class="md-toc-inner" href="#there-is-safety-in-numbers-applying-theories-of-social-bonding-to-a-live-western-art-music-concert-audience-katherine-oneill-hauke-egermann">‘There is Safety in Numbers’: Applying theories of social bonding to a live, Western Art Music concert audience (<em>Katherine O'Neill, Hauke Egermann</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1807"><a class="md-toc-inner" href="#-n1807"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n50"><a class="md-toc-inner" href="#paper-session-9">Paper Session 9</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1185"><a class="md-toc-inner" href="#togetherness--music-and-prosociality"> Togetherness / Music and Prosociality</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n51"><a class="md-toc-inner" href="#-n51"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1017"><a class="md-toc-inner" href="#music-prosocial-engagement-and-alzheimers-disease-a-scoping-review-and-meta-analysis-aaron-colverson">Music, prosocial engagement, and Alzheimer's disease: a scoping review and meta-analysis (<em>Aaron Colverson</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n125"><a class="md-toc-inner" href="#-n125"></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1023"><a class="md-toc-inner" href="#the-social-dimensions-of-collaborative-playlist-making-involved-social-processes-and-promoted-prosocial-consequences-ilana-harris-ian-cross">The Social Dimensions of Collaborative Playlist-Making: Involved Social Processes and Promoted Prosocial Consequences (<em>Ilana Harris, Ian Cross</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h6" data-ref="n1812"><a class="md-toc-inner" href="#-n1812"></a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1031"><a class="md-toc-inner" href="#closing-remarks">Closing Remarks</a></span></p></div><hr /><h1><a name="tuesday-september-15th" class="md-header-anchor"></a><span>Tuesday, September 15th</span></h1><hr /><h2><a name="opening-remarks" class="md-header-anchor"></a><span>Opening Remarks</span></h2><p><span>																					</span><span>09:30 - 10:00 </span></p><h6><a name="-n1997" class="md-header-anchor"></a></h6><hr /><h2><a name="keynote" class="md-header-anchor"></a><span>Keynote </span></h2><p><span>																							</span><span>(tba) </span></p><p><span>																					</span><span>10:00 - 11:00 </span></p><h6><a name="-n1999" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-1" class="md-header-anchor"></a><span>Paper Session 1</span></h2><h3><a name="communication-and-meaning" class="md-header-anchor"></a><span>Communication and Meaning</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n1737" class="md-header-anchor"></a></h6><p><span>11:30 - 11:50 </span></p><h5><a name="communication-of-musical-meaning-from-text-through-improvisation-to-the-listener-helena-dukic-richard-parncutt" class="md-header-anchor"></a><span>Communication of musical meaning from text, through improvisation to the listener (</span><em><span>Helena Dukic, Richard Parncutt</span></em><span>)</span></h5><p><span>To what extent can a musical improviser communicate the meaning of a short text to an audience? Four pianists read and improvised on nine haikus, three of which focused on animals and their movements, three on human emotions and three on the natural environment. Then they described how they felt about the haiku and how they imagined associated movements. Improvisations were played to 17 school children which tried to describe the feelings and movements of the story’s subject. Three independent coders coded to six basic emotions (Happiness, Sadness, Anger, Fear, Surprise, Disgust) and ten movement types (Fast, Slow, Regular, Irregular, Up, Down, Big, Small, Smooth, Rough).There was a significant correlation between pianists’ intentions and listeners’ perceptions for Happiness, Anger, Surprise, Fear, and Disgust, but not for Sadness; and for movement types Slow, Fast, Irregular, Up, Down and Rough, but not for Regular, Big, Small, Smooth.</span></p><h6><a name="-n812" class="md-header-anchor"></a></h6><p><span>11:50 - 12:10</span><span>	</span></p><h5><a name="musical-pragmatics-an-interdisciplinary-approach-to-musical-meaning-patricia-dreesbach" class="md-header-anchor"></a><span>Musical Pragmatics: An Interdisciplinary Approach to Musical Meaning (</span><em><span>Patricia Dreesbach</span></em><span>)</span></h5><p><span>Music is meaningful in multifarious ways: it can communicate messages, evoke emotions and has social relevance. A common approach to investigate the meaning of music is to apply linguistic methods to music. The meaning of language is mainly connected to semantics and pragmatics. The author&#39;s focus lies on pragmatics to approach musical meaning. Through applying fields of pragmatics to music, a better understanding of how music can convey meaning and how the perceiver can understand this meaning is reached. In a theory-based approach the main concepts of pragmatics, which are deixis, speech acts, presupposition, implicature and conversation structure, will be transferred onto music. The comparison shows that there are many parallels between pragmatics and musical meaning. Because of these similarities, pragmatics does not seem to be an entirely linguistic phenomenon but rather a general cognitive competence which is important to convey and understand meaning. This competence might be connected to the “Theory of Mind”.</span></p><h6><a name="-n1742" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-2" class="md-header-anchor"></a><span>Paper Session 2</span></h2><h3><a name="computational-modelling-and-audio-processing" class="md-header-anchor"></a><span> Computational Modelling and Audio Processing</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n9" class="md-header-anchor"></a></h6><p><span>13:00 - 13:20</span><span>	</span></p><h4><a name="effect-of-musical-training-in-preserving-the-temporal-and-spatial-hearing-processing-abilities-in-elderly-adults-sreeraj-konadath-ranjini-dorai-k-v-nisha" class="md-header-anchor"></a><span>Effect of musical training in preserving the temporal and spatial hearing processing abilities in elderly adults (</span><em><span>Sreeraj Konadath, Ranjini Dorai, K. V. Nisha</span></em><span>) </span></h4><p><span>The present study aimed to determine the effect of musical training on  binaural, spatial, and temporal processing abilities in elderly  listeners with normal hearing. A test battery consisting of the temporal processing (gap detection threshold-GDT),  binaural processing  (inter-aural time and inter-aural level difference thresholds) and  spatial processing (virtual acoustic space identification test &amp; SSQ  questionnaire) measures were carried out on two groups of listeners  (age: 41 to 70 years, Group I: Musicians N=15, mean age 52.5 ± 2.1 y;  range: 42 – 66.5yGroup II: Non- Musicians N=15, mean age 56.75 ± 2.8 y;  range: 41 – 68 y). Statistical analyses using MANOVA and Mann-Whitney U  showed musicians performed significantly better (p&lt;0.05) than their  age-matched non-musician counterparts in all the tests. The findings of  the study thus highlight the positive outcomes of musical training on  counter-acting age-related auditory processing deficits.</span></p><h6><a name="-n11" class="md-header-anchor"></a></h6><p><span>13:20 - 13:40 </span></p><h4><a name="modelling-large-scale-thematic-structure-in-music-edward-hall-marcus-pearce" class="md-header-anchor"></a><span>Modelling Large-Scale Thematic Structure in Music (</span><em><span>Edward Hall, Marcus Pearce</span></em><span>)</span></h4><p><span>Large-scale structure is valued highly in music theory and in many models of cognition, however, strong evidence in support of its perception is scarce. It becomes more elusive still when considering thematic (opposed to tonal) structures. To provide the nuanced approach this topic obviously necessitates, a computational model of possible cognitive processes facilitating the perception of large-scale thematic coherence is created, applied to a corpus of extracted monophonic melodies, and tested with a study. Repetition forms the basis of this model. Through statistical learning, repetition of material causes it to become salient, and creates a sense of coherence. By seeking salient themes and subsequent related repetitions, the model produces a set of measures that can describe the items of the corpus in terms of their structurally important features, finding they systematically vary, as structure does in the corpus. A subsequent study tests behaviourally three of these measures from the model’s output.</span></p><h6><a name="-n14" class="md-header-anchor"></a></h6><p><span>13:40 - 14:00  </span></p><h4><a name="analysis-of-lip-flow-in-trumpet-playing-using-iterative-adaptive-inverse-filtering-gustavo-machado-oliveira-davi-mota-maurício-loureiro" class="md-header-anchor"></a><span>Analysis of lip flow in trumpet playing using iterative adaptive inverse filtering (</span><em><span>Gustavo Machado Oliveira, Davi Mota, Maurício Loureiro</span></em><span>)</span></h4><p><span>Lip control is an essential element of trumpet performance technique.  This study departs from the source-filter model approach to voice  production for estimating the airflow passing through the player’s lips  at the mouthpiece. Direct measurement of the air pulse signal passing  through the lips is complicated and invasive. We proposed to model the  trumpet sound production by inverse filtering using an algorithm  proposed by P. Alku (1992) for voice production analysis. We were able  to obtain the excitation patterns produced by the lips by applying the  inverse of the trumpet tube transfer function to the output signal  captured at the instrument bell for different pitches. Five milliseconds segments, where the signal presented the highest spectral stability,  were used. Skewness and kurtosis values of one cycle of the obtained lip flow signal exhibited individual differences of lip control, between  performances of players with different experience levels, which also  varied according to note pitch. The method presented promising results  for modeling trumpet sound production.</span></p><h6><a name="-n1751" class="md-header-anchor"></a></h6><hr /><h2><a name="poster-session-1" class="md-header-anchor"></a><span>Poster Session 1</span></h2><p><span>																					</span><span>14:15-15:15  </span></p><hr /><h6><a name="-n170" class="md-header-anchor"></a></h6><h4><a name="paralysis-by-analysis-effects-of-focus-of-attention-on-acoustic-and-motion-parameters-in-open-string-violin-bowing-emma-allingham--clemens-wöllner" class="md-header-anchor"></a><span>“Paralysis by analysis”: Effects of focus of attention on acoustic and motion parameters in open string violin bowing (</span><em><span>Emma Allingham,  Clemens Wöllner</span></em><span>)</span></h4><p><span>We tested the effect of focus of attention on motor performance in violin bowing. Research in sports psychology shows that focusing on body movement compared to focusing on the task goal impairs performance, and the further the focus from the body, the better the performance (Wulf, 2013). This has not been tested before in violin playing. Performance outcomes measured were: tone quality (acoustic analysis), technical bowing parameters (motion capture), and instrument sway (i.e freedom of body motion, motion capture). 16 experts and 16 beginners played open strings under three foci: internal: focusing on arm movement, external: focusing on sound, somatic: focusing on tactile sensing. We hypothesised that focus condition would affect acoustic features of sound and motion parameters. Results showed that somatic focus increased spectral centroid (brightness), bow-bridge distance consistency, and instrument sway (i.e freedom of motion, beginners only). We suggest the somatic focus may be a preferable external focus strategy for violinists than focusing on sound.</span></p><h6><a name="-n605" class="md-header-anchor"></a></h6><h4><a name="a-case-study-on-music-education-in-19th-century-giardini-dinfanzia-giovanna-carugno" class="md-header-anchor"></a><span>A Case Study on Music Education in 19th Century Giardini d’Infanzia (</span><em><span>Giovanna Carugno</span></em><span>)</span></h4><p><span>This paper aims at filling a gap within the  music pedagogy scholarly literature, by providing a historical overview  of the musical activities organized in the 19th century Italian  &quot;giardini d’infanzia&quot;. The model of these preschools, based on the  Froebelian &quot;kindergarten&quot;, will be compared to that represented by the  &quot;asili di carità&quot;, founded by the pedagogue Ferrante Aporti and  administered by religious entities. </span></p><p><span>The research was carried out by analysing primary and secondary sources, including  teachers’ handbooks, iconographical resources, and collections of songs, addressed to children aged 3-6.  </span></p><p><span>The paper  demonstrates that music acquired an important role in the “giardini  d’infanzia”, even if it was not conceived as a separate or autonomous  subject within the preschool curriculum. In fact, musical activities  were often proposed as an accompaniment of gymnastic and marching games. Compared to the experience of “asili di carità”, the teachers adopted  an active way of teaching, by playing and interacting with the children  through the use of Froebelian gifts. </span></p><h6><a name="-n607" class="md-header-anchor"></a></h6><h4><a name="an-exploration-of-the-musical-or-sonic-properties-of-language---from-auditory-perception-to-interpretation-of-meaning-celia-denore-lopez" class="md-header-anchor"></a><span>An exploration of the musical (or sonic) properties of language - from auditory perception to interpretation of meaning (</span><em><span>Celia Denore Lopez</span></em><span>)</span></h4><p><span>This study explores the application in creative practice of existing research on the links between language and music and the relevance of this practice to possible future research. As a performer and composer I created musical pieces based on texts in four different languages, both through the approximate transcription of speech to musical notation and through musical improvisations of various musicians based on their perception of the text. Removing the direct meaning attached to utterances in each language led to an exploration of the sonic qualities that, although not having direct meaning, may play a significant role in how we respond to and interact with language. Through this example of musical practice I aim to challenge the notion of language having direct meaning, and music indirect meaning (or ‘floating intentionality’, Cross, 2014), as we explore how the sonic properties of both may contribute in similar ways to effect on the listener.</span></p><h6><a name="-n610" class="md-header-anchor"></a></h6><h4><a name="personality-traits-and-reasons-of-daily-music-listening-are-associated-with-the-experience-of-groove-deniz-duman-petri-toiviainen-geoff-luck" class="md-header-anchor"></a><span>Personality Traits and Reasons of Daily Music Listening are Associated with the Experience of Groove (</span><em><span>Deniz Duman, Petri Toiviainen, Geoff Luck</span></em><span>)</span></h4><p><span>Groove, an important element of popular music, is defined as the quality of music associated with wanting to move and positive affect. With the aim of understanding how personality traits and reasons of daily music listening are associated with people’s groove experiences, an online listening study was conducted. Participants (N=105) completed questionnaires, listened to 30 musical excerpts from popular songs with various genre and groove categories and finally evaluated their experiences for each track. Aligned with previous reports, liking (r=.68, p&lt;.000) and familiarity (r=.47, p&lt;.000); as well as extraversion (r=.28, p=.002) and participants’ self-evaluation of finding dancing easy (r=.48, p&lt;.000) significantly correlated with desire to move. Moreover, a factor analysis for 21 items of reasons of music listening yielded a 3-factor model (categorized as: “energy/emotion”, “self/identity” and “social/connection”). Finally, all variables were included in a stepwise multiple linear regression model which predicted 55% of variance in desire to move.</span></p><h6><a name="-n613" class="md-header-anchor"></a></h6><h4><a name="message-and-medium-in-musical-performance--intersemiotics-aspects-of-the-music-representation-marina-cesar" class="md-header-anchor"></a><span>Message and medium in musical performance : intersemiotics aspects of the music representation (</span><em><span>Marina Cesar</span></em><span>)</span></h4><p><span>Historically, performance as a musical practice in musicology initially separates from its more theoretical side. The first works on the semiotics of music also followed this current, assuming a structuralist base that privileges the score&#39;s code to the detriment of the musical act. These points of view have evolved over the years and currently offer new clarifications on music action and its representation. In this paper, we will discuss the relation between the analysis of the musical notation and representation and performance to explore the connections between semiotics and musicology. In realizing this objective, we examine the differences in the relations between the work and the performance, which implies an analytical divide concerning the analysis of production in the arts (performance studies) and that which more specifically affects music (performance practice studies). To do so, we will use the recent developments in visual and tensive semiotics to relate expression and content in a text according to sensible and more continuous categories and the tension created by these categories. Within this paper&#39;s context, we will also undertake an analysis based on the literature of the concerns regarding the visual representation or the notation of the musical act. These concerns are present in ethnomusicology and allow the establishment of a theory of musical performance that sets music-making as a benchmark (Blacking, 1979; Stock, 1997). This point of view has its origin in the definition of musical analysis as a description of sequences of different types of creative acts paying particular attention to the kinds of collaborations established between musicians. Such research has led to other studies involving the musical representation itself and its visuality (Blum, 2006; Elliot, 1995). Our findings propose a revaluation of music as performance art to bridge the gap between the visual aspect of notation and performance as the lived experience of the audience.</span></p><h6><a name="-n817" class="md-header-anchor"></a></h6><h4><a name="the-size-of-musical-awe-correlations-of-musical-features-and-the-perceptions-of-virtual-size-landon-peck" class="md-header-anchor"></a><span>The size of musical awe: Correlations of musical features and the perceptions of virtual size (</span><em><span>Landon Peck</span></em><span>)</span></h4><p><span>Size, power and vastness are all attributes hypothesised to provide a fundamental source for experiences of awe. This study presents an experiment that investigates the relationship between musical features of awe-related music and its perceived size.The principal ecological factor in the relationship between size and music is amplitude (loudness), this factor was accounted for by use of a between-subjects design that divided participants into two groups: uncompressed music and compressed music. Participants listened to different awe-related music samples and controlled a potentiometer that changed the size of a computer-generated sphere in real time.Expected results are hypothesised to show significant correlations of size with amplitude in the uncompressed music condition and spectral brightness within compressed music.These expected results suggest that hidden underneath the associations of amplitude and size are other spectral associations related to musical size in awe-related music.</span></p><h6><a name="-n616" class="md-header-anchor"></a></h6><h4><a name="inaudible-frequencies-in-the-context-of-scientific-studies-with-music-claudia-stirnat" class="md-header-anchor"></a><span>Inaudible Frequencies in the Context of Scientific Studies with Music (</span><em><span>Claudia Stirnat</span></em><span>)</span></h4><p><span>When preparing and conducting scientific studies, several requirements have to be fulfilled such as investigating real facts or issues and the reproducibility of same results using the same experimental design. Live-music of non-electronical instruments, e.g. symphony orchestra or ensembles, contains a frequency spectrum that exceeds the ability on human perception of 20kHz. When using recorded music instead of live performances to ensure the reproducibility of experiments or measurements (e.g. in acoustical studies), usually the frequency spectrum is cut off at a certain frequency depending on the technology used from recording to playback. This means a part of music in live performances gets lost and an incomplete live situation is simulated. This paper will introduce existing studies about high, inaudible frequencies in the context of music and will discuss the results what can be concluded about the importance of high, inaudible frequencies in music. As a clear conclusion cannot be made by the current state of research, arguments in favour and against the importance of inaudible frequencies will summarized. Based on Joshua D. Reiss’ meta-analysis of high resolution audio perceptual evaluation (2016) some of those studies being reliable will be included. Also studies not part in the meta-analysis are subject here such as Fukushima et al 2014 (or Koubori etal. 2010.) that focus more on the unconscious processing through brain stimulation. This will provide an outline for future research to further investigate the question of high, inaudible frequencies in music.</span></p><h6><a name="-n620" class="md-header-anchor"></a></h6><h4><a name="the-computer-notation-musica-anna-terzaroli" class="md-header-anchor"></a><span>The computer notation: MUSICA (</span><em><span>Anna Terzaroli</span></em><span>)</span></h4><p><span>The research concerns the possibility of the symbolic notation of sound  events by a computer. The actual software systems designed to perform  this function are manifold, these are constantly being updated and new  ones are developed. We mention, among the others, Lilypond and GUIDO and, among the oldest, Score.</span>
<span>In the early Seventies of  1900, at Padua, Giovanni De Poli develops MUSICA, one of the first  symbolic notation systems of music to write down the characters used in  traditional music. MUSICA, as stated by Debiasi and De Poli (1982), &quot;is a transcription of  musical language in texts for computers... rules that allow you to write down any musical text, written in conventional notation, in a notation  adapted to the recognition, storage and manipulation by the computers... from the conventional notation to an isomorphic notation with the first one... this transcription language presents, over the isomorphism, the  following particularities: a) ease of learning and use by the mnemonic  way; b) economy in the transcription work using shorthand or implied  notations; c) coding on a single line in a single pass; d) indipendence  from planned use types and adaptability to any situation using any  special additional notations.&quot;</span>
<span>Dealing with this case of study is  especially significant because G. De Poli designing and implementing  MUSICA raises the question of what the symbolic representation is really possible and how however a &quot;gap&quot;remains between the representation of  music and music itself. Furthermore, this question, to date, had no  solution, so this problem is open and available for the research  investigation.</span></p><h6><a name="-n622" class="md-header-anchor"></a></h6><h4><a name="evaluation-system-for-ai-based-music-generation-models-zongyu-yin-federico-reuben-tom-collins" class="md-header-anchor"></a><span>Evaluation System for AI-based Music Generation Models (</span><em><span>Zongyu Yin, Federico Reuben, Tom Collins</span></em><span>)</span></h4><p><span>Research on AI music generation models does not adhere to a standard  evaluation method, hampering the ability to compare models and generated results. We aim to provide an evaluation system as a general framework  for AI music generation models. A listening study will be conducted  using a mix of human-composed and AI-generated string quartets and  classical piano improvisations, collecting both quantitative and  qualitative data from participants. As well as constituting a  comparative evaluation, participant data will be used to build a  predictive model, revealing which features of human-composed and  AI-generated content lead to high or low ratings of stylistic success.  In future, researchers will able to use our predictive model to derive  estimates of the relative stylistic strengths and weaknesses of their AI music generation models.</span></p><h6><a name="-n1753" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-3" class="md-header-anchor"></a><span>Paper Session 3 </span></h2><h3><a name="pandemicusicology---musical-behaviour-in-times-of-covid-19" class="md-header-anchor"></a><span>Pandem(ic)usicology - Musical Behaviour in Times of Covid-19</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n18" class="md-header-anchor"></a></h6><p><span>15:30 - 15:50</span><span>	</span></p><h4><a name="virtually-together-concerts-during-the-coronavirus-dana-swarbrick" class="md-header-anchor"></a><span>Virtually Together: Concerts during the Coronavirus (</span><em><span>Dana Swarbrick</span></em><span>)</span></h4><p><span>Government responses to the coronavirus led to unprecedented social distancing measures across the world. These measures were challenging however, musicians adapted by providing online concerts. Anecdotally, viewers commented that virtual concerts made them feel socially connected despite the restrictions and the technologically mediated interactions. However, the aspects of what promote togetherness in a virtual concert remain unknown. We aimed to ask two questions using an extensive online survey: what aspects of the concert experience and personal characteristics 1) make people feel social connection and 2) make people feel moved? 310 participants from 14 countries across America, Europe, and Asia completed the survey. The main outcomes were the Kama Muta Scale (Zickfeld et al., 2019) and social connection to the performers and other audience members. This research addresses the topical question of how people can feel socially connected in a time of social distancing.</span></p><h6><a name="-n20" class="md-header-anchor"></a></h6><p><span>15:50 - 16:10</span><span>	</span></p><h4><a name="listening-niches-on-spotify-before-and-during-the-covid-19-pandemic-emily-hurwitz-carol-krumhansl" class="md-header-anchor"></a><span>Listening Niches on Spotify Before and During the COVID-19 Pandemic (</span><em><span>Emily Hurwitz, Carol Krumhansl</span></em><span>)</span></h4><p><span>This study investigates how undergraduate students’ music listening niches on Spotify changed in the four weeks immediately after they left campus abruptly due to the COVID-19 pandemic. Participants provided a list of their most frequently listened-to songs during this period of time. 133 undergraduates (38 males, 92 females, 4 non-binary, mean age = 20.3) identified one song that seemed strongly associated with this period and stated why this song seemed particularly relevant. These reasons were coded on a number of underlying factors, and songs that matched these factors especially well were identified. Four factors were found to underlie the reasons given: (1) emotion (positive, negative, and mixed); (2) person and nostalgia; (3) place and event (other than pandemic); (4) discovered during the pandemic. The latter factor was related to an increased use of tools to find new music. We identified songs and reasons for selecting that represented these four factors.</span></p><h6><a name="-n1762" class="md-header-anchor"></a></h6><hr /><p><span>17:00 - 19:00 </span></p><h4><a name="lunch-and-dinner-across-time-zones" class="md-header-anchor"></a><span>Lunch and Dinner across Time zones</span></h4><p><span>Even though the conference online, we can still socialise! Bring some food and/or a drink and network with other SysMus people! We will distribute a separate link for this meeting closer to the event.</span></p><h6><a name="-n1764" class="md-header-anchor"></a></h6><hr /><h1><a name="wednesday-september-16th" class="md-header-anchor"></a><span>Wednesday, September 16th</span></h1><hr /><h6><a name="-n898" class="md-header-anchor"></a></h6><p><span>01:00 - 03:00 </span></p><h4><a name="breakfast-and-dinner-across-time-zones" class="md-header-anchor"></a><span>Breakfast and Dinner across Time zones</span></h4><p><span>Even though the conference online, we can still socialise! Bring some food and/or a drink and network with other SysMus people! We will distribute a separate link for this meeting closer to the event.</span></p><h6><a name="-n1768" class="md-header-anchor"></a></h6><hr /><p><span>08:00 - 09:30 </span></p><h4><a name="breakfast--lunch--dinner-across-time-zones" class="md-header-anchor"></a><span>Breakfast / Lunch / Dinner across Time zones</span></h4><p><span>Even though the conference online, we can still socialise! Bring some food and/or a drink and network with other SysMus people! We will distribute a separate link for this meeting closer to the event.</span></p><h6><a name="-n1770" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-4" class="md-header-anchor"></a><span>Paper Session 4</span></h2><h3><a name="music-across-cultures" class="md-header-anchor"></a><span>Music Across Cultures</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n1151" class="md-header-anchor"></a></h6><p><span>10:00 - 10:20</span><span>	</span></p><h4><a name="invention-of-jīva-jeya-nātam-innovative-musicology-and-democratization-of-music-in-post-war-sri-lanka-pathmanesan-sanmugeswaran" class="md-header-anchor"></a><span>Invention of Jīva Jeya Nātam: Innovative Musicology and Democratization of Music in Post-war Sri Lanka (</span><em><span>Pathmanesan Sanmugeswaran</span></em><span>)</span></h4><p><span>This paper illustrates an ethnomusicological study of the innovative musicology and the cultural history of Jīva Jeya Nātam in post-war Sri Lanka. Jīva Jeya Nātam is, a string instrument invented by a musician, Mr. N. Jeyaneethan, from Trincomalee District of Sri Lanka in 2019. Jīva Jeya Nātam differs from other Carnatic music (Indian classical music) instruments in various ways. This can be played as a main instrument as well as an accompaniment in the Carnatic music ensemble. The innovative religious-mythical foundations were to earn recognition and publicity like other Carnatic music instruments. Furthermore, Jeyaneethan’s innovative musicology restructures the musical spaces and democratizes Carnatic music in Sri Lanka. However, many challenges, obstacles, and problems have emerged in terms of power, knowledge, and hierarchy within the cultural history of this musical craftwork. Ethnographic research methods were used to collect data in this study.</span></p><h6><a name="-n638" class="md-header-anchor"></a></h6><p><span>10:20 - 10:40</span><span>	</span></p><h4><a name="chinese-whispers-choral-singing-in-a-second-language-eloise-mccann" class="md-header-anchor"></a><span>Chinese Whispers: Choral Singing in a Second Language (</span><em><span>Eloise McCann</span></em><span>)</span></h4><p><span>This study investigated the emotional experiences reported by singers when rehearsing and performing songs in a non-native language and examined how learning experiences changed as repertoire and language became familiar. Semi-structured interviews took place with adult choir members (n = 15) and children’s choir teachers (n = 6) following a term of Mandarin choir rehearsals and a concert performance. Four key findings emerged. First, age was a noteworthy factor in the learning process and in retaining text. Second, repetition of Mandarin text within songs and use of familiar tunes helped to ease the learning process for both adults and children. Third, assigning meaning to the text through actions encouraged understanding of the text for children. Finally, the emotional experiences of members aligned with previous research, namely singing together creates bonds between choir members and creates an overall positive experience (Gabrielsson 2011). Further research will provide insight into experiences of other choir participants and explore the benefits of Mandarin choir rehearsals in supporting language tuition.</span></p><h6><a name="-n636" class="md-header-anchor"></a></h6><p><span>10:40-11:00 </span></p><h4><a name="same-but-different---cross-cultural-comparison-of-ioi-pattern-distribution-in-rhythm-reproduction-of-school-children-gesine-wermke" class="md-header-anchor"></a><span>Same but different? - Cross-cultural Comparison of IOI pattern distribution in Rhythm Reproduction of School-Children (</span><em><span>Gesine Wermke</span></em><span>)</span></h4><p><span>Same but different? - Cross-cultural Comparison of IOI pattern distribution in Rhythm Reproduction of School-ChildrenFrom an ontogenetic perspective, distinctive characteristics of rhythmical behaviour and the multisensory perception of rhythm is also imprinted by a person’s cultural upbringing or background (e.g. Savage et al., 2015; Yates et al., 2017; Polak et al., 2018). This investigation is part of a broad analysis of rhythm-reproduction patterns of two groups of children. The overall aim of the study is to separate music culture-related perception of rhythmic patterns from universals in rhythm perception and production. At the conference I will report results regarding certain musical features, e.g. stressing of beats, syncopation or length of notes. Nso (Cameroonian) and German children were recorded reproducing different stimuli with their preferred finger or a pencil. IOIs were determined used to characterize different patterns. The analysis of the data is still under work. Preliminary results however indicate different IOI reproduction patterns, which seems to support cultural specifics in the reproduction of a perceived rhythm.</span></p><h6><a name="-n1775" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-5" class="md-header-anchor"></a><span>Paper Session 5</span></h2><h3><a name="the-effect-of-musical-features-on-altered-states-of-consciousness" class="md-header-anchor"></a><span>The effect of musical features on altered states of consciousness</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n59" class="md-header-anchor"></a></h6><p><span>11:30 - 11:50 </span></p><h4><a name="assessing-properties-of-music-for-sleep--and-relaxation-rory-kirk-tim-metcalfe-maan-van-de-werken-renee-timmers" class="md-header-anchor"></a><span>Assessing properties of music for sleep  and relaxation (</span><em><span>Rory Kirk, Tim Metcalfe, Maan van de Werken, Renee Timmers</span></em><span>)</span></h4><p><span>Many people find that music helps with sleep (Trahan et al., 2018) and music has been studied for its efficacy as a clinical intervention. However, there remain questions surrounding what particular aspects of music best promote sleep, and the underlying mechanisms involved (Jespersen et al., 2015). </span>
<span>Here we present the design of a forthcoming study that will investigate which characteristics are most suitable for music for sleep, as compared to music for other purposes. This study forms the first stage of a wider project aimed at developing a device that uses biofeedback to facilitate sleep. A listening experiment will gather subjective and physiological data to map musical characteristics with participant states, taking into consideration notions of arousal, emotions, and engagement (Jespersen &amp; Vuust, 2012). Outcomes will inform successive stages that will explore the effects of music on real sleep behaviours.</span></p><h6><a name="-n916" class="md-header-anchor"></a></h6><p><span>11:50-12:10 </span></p><h4><a name="ceremonial-and-recreational-use-of-music-supporting-psychedelic-trips-a-large-scale-musical-feature-study-christine-ahrends-ole-heggli-jan-stupacher-orla-mallon-lasse-damgaard-morten-kringelbach-peter-vuust" class="md-header-anchor"></a><span>Ceremonial and recreational use of music supporting psychedelic trips: a large-scale musical feature study (</span><em><span>Christine Ahrends, Ole Heggli, Jan Stupacher, Orla Mallon, Lasse Damgaard, Morten Kringelbach, Peter Vuust</span></em><span>)</span></h4><p><span>Across cultures and throughout history, psychedelics have been intimately linked with music, suggesting that music serves a fundamental function. To support recent psychedelic therapy approaches, it is crucial to understand what type of music can be used to create a positive and safe experience under psychedelics. We here aimed to identify common features of music that experienced users of psychedelics choose for their trips. We extracted musical features from audio files (n = 90000) that are used ceremonially or recreationally during psychedelic trips. We analysed these features for most prevalent common patterns and their predictive power in classifying music for psychedelics compared to a control set of popular songs. We found that musical pieces used in psychedelic ceremonies show small variance across tempo- and meter-related musical features. These findings point towards musical predictability as an important factor for a beneficial psychedelic setting. We will use these results to inform a neuroimaging study to understand how music can affect the brain under psychedelics.</span></p><h6><a name="-n1781" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-6" class="md-header-anchor"></a><span>Paper Session 6</span></h2><h3><a name="music-and-memory" class="md-header-anchor"></a><span>Music and Memory</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n33" class="md-header-anchor"></a></h6><p><span>14:30 - 14:50</span><span>	</span></p><h4><a name="models-of-memory-for-music-too-many-theories-or-not-enough-ana-marta-pacheco-aguiar" class="md-header-anchor"></a><span>Models of Memory for Music: Too Many Theories or Not Enough? (</span><em><span>Ana Marta Pacheco Aguiar</span></em><span>)</span></h4><p><span>Cognitive frameworks of memory have been evolving over the last 40 years, with the declarative-non-declarative theory being called into question and suggestions about different processing components and process-specific alliances being put forward (Cabeza &amp; Moscovitch, 2013). In relation to music, Chaffin et al. (2016) suggest a difference between associative chains (unconsciously obtained) and content addressable memory (consciously obtained), proposing that this may explain how musicians are able to play complex pieces by memory in a performance setting. However, questions about memory for specific music in a performer’s perspective seems to not be answered in neither field. Therefore, cognitive frameworks of memory and discussion of memory and music seem to warrant further exploration and clarification. In this paper, theories of memory of Music Psychology and Cognitive Psychology and Neuroscience will be presented, questions and concerns will be discussed for both fields, and possible future research will be proposed.</span></p><h6><a name="-n634" class="md-header-anchor"></a></h6><p><span>14:50 - 15:10</span><span>	</span></p><h4><a name="music-evoked-autobiographical-memory-retrieval-in-healthy-populations-future-directions-for-a-unified-research-methods-approach-tara-henechowicz-michael-thaut" class="md-header-anchor"></a><span>Music-Evoked Autobiographical Memory Retrieval in Healthy Populations: Future directions for a Unified Research Methods Approach (</span><em><span>Tara Henechowicz, Michael Thaut</span></em><span>)</span></h4><p><span>Introduction. Although individual differences in visual imagery, emotion, and self-referential processing may explain variability in autobiographical memory (AM) retrieval (Palombo et al., 2018), individual differences in Music-Evoked Autobiographical Memories (MEAMs) warrant systematic examination. Thus, the aim of this review is to assess whether individual differences in emotion processing and visual imagery explain variation in MEAMs. Methods. Two searches were conducted and studies using musical cues to evoke AMs in healthy populations were included. Results. We included N=18 total studies with N=15 group differences investigations and N=3 individual differences studies. Emotion processing and visual imagery play a role in MEAM retrieval and individual differences in these processes may explain variance in MEAMs. Reward processing may also underlie individual differences. Conclusion. A unified approach of individual and group differences will give us a systematic understanding of the role of emotional processing, visual imagery, and reward processing in MEAM retrieval.</span></p><h6><a name="-n1786" class="md-header-anchor"></a></h6><hr /><p><span>17:00 - 19:00 </span></p><h4><a name="lunch-and-dinner-across-time-zones-n1058" class="md-header-anchor"></a><span>Lunch and Dinner across Time zones</span></h4><p><span>Even though the conference online, we can still socialise! Bring some food and/or a drink and network with other SysMus people! We will distribute a separate link for this meeting closer to the event.</span></p><h6><a name="-n1788" class="md-header-anchor"></a></h6><hr /><h1><a name="thursday-september-17th" class="md-header-anchor"></a><span>Thursday, September 17th</span></h1><hr /><h6><a name="-n1049" class="md-header-anchor"></a></h6><p><span>01:00 - 03:00 </span></p><h4><a name="breakfast-and-dinner-across-time-zones-n1042" class="md-header-anchor"></a><span>Breakfast and Dinner across Time zones</span></h4><p><span>Even though the conference online, we can still socialise! Bring some food and/or a drink and network with other SysMus people! We will distribute a separate link for this meeting closer to the event.</span></p><hr /><h6><a name="-n1045" class="md-header-anchor"></a></h6><p><span>08:00 - 09:30 </span></p><h4><a name="breakfast--lunch--dinner-across-time-zones-n1046" class="md-header-anchor"></a><span>Breakfast / Lunch / Dinner across Time zones</span></h4><p><span>Even though the conference online, we can still socialise! Bring some food and/or a drink and network with other SysMus people! We will distribute a separate link for this meeting closer to the event.</span></p><h6><a name="-n1794" class="md-header-anchor"></a></h6><hr /><h2><a name="poster-session-2" class="md-header-anchor"></a><span>Poster Session 2</span></h2><p><span>																					</span><span>10:00 - 11:00</span></p><hr /><h6><a name="-n316" class="md-header-anchor"></a></h6><h4><a name="revisiting-the-general-chord-type-gct-representation-a-novel-refined-algorithm-konstantinos-giannos-emilios-cambouropoulos" class="md-header-anchor"></a><span>Revisiting the General Chord Type (GCT) representation: a novel refined algorithm (</span><em><span>Konstantinos Giannos, Emilios Cambouropoulos</span></em><span>)</span></h4><p><span>There are multiple ways of encoding chords symbolically; however, they  are used by different practices and applied only to specific musical  idioms. Recently, a novel chord encoding attempted to bridge the gap and be flexible enough to adapt in numerous musical idioms. The aim of the  current study is to propose a new algorithm, one that re-arranges a  given collection of pitch classes more elegantly than the original,  utilizing the quality of intervals between successive pitches and  between the root and each chord pitch. The encoding deals effectively  with tonal chords with atypical extensions or additions, fitting the  stack-of-thirds methodology. Also, handles well non-tonal chords being  able to output the normal orders of pc-set theory, or other non-triadic  chords, built οn seconds, fourths, or fifths. Such a system has  important implications to automatic harmonic analysis and reduction.</span></p><h6><a name="-n944" class="md-header-anchor"></a></h6><h4><a name="digital-habitats-for-interdisciplinary-music-research-sebastian-klaßmann-nils-dahmen" class="md-header-anchor"></a><span>Digital habitats for interdisciplinary music research (</span><em><span>Sebastian Klaßmann, Nils Dahmen</span></em><span>)</span></h4><p><span>Computation is a core concept for the sciences, arts and society of the  21st century. It requires computational thinking and literacy which  become increasingly central for interdisciplinary music research.  Although there are computational approaches in interdisciplinary music  research, an integrating framework is missing. The conception of a  digital habitat is proposed as a candidate for integrating computational concepts in interdisciplinary music research and teaching.  Technologically, our long-term case study explores a configuration  mainly based on Jupyter Notebook, HackMD and Python as a digital  habitat. As a social environment for research and teaching, it explores  structures for communal interaction and relevant computational and  scientific concepts. Our case study shows that this configuration  supports the fostering of computational thinking and literacy, as well  as the formation of computationally native learning communities in a  digital habitat. In sum, the explored configuration supports digital  habitats for research and teaching in interdisciplinary music research  today.</span></p><h6><a name="-n949" class="md-header-anchor"></a></h6><h4><a name="mimesis-and-kinaesthesia-in-music----a-behavioural-studyanna-kolesnikov-joshua--bamford-eduardo-andrade" class="md-header-anchor"></a><span>Mimesis and kinaesthesia in music – a behavioural study(</span><em><span>Anna Kolesnikov, Joshua  Bamford, Eduardo Andrade</span></em><span>)</span></h4><p><span>Drawing on the framework of embodied music cognition (Cox, 2011), this  paper investigates perceived motion and embodied music experience in  non-musicians across three musical dimensions: melodic contour, melodic  complexity and, following from Hanson and Huron (2019), note pattern. 27 ten-second piano tracks were created in close collaboration with  composer Eduardo Andrade. Participants were screened for musical  experience and after listening to each stimulus used a VAS to rate them  for perceived movement, rotation, and emotional and physical  involvement. Results showed that quaternary note pattern and ascending  melodies received significantly higher ratings for physical involvement, movement and rotation, and high complexity melodies received  significantly higher ratings for movement and emotional involvement.  Greater bodily engagement evoked by ascending melodies may be modulated  by greater perceived ‘effort’ to reach higher pitches, and future  studies are needed to verify whether perceived rotation is driven by  note pattern or note density and pitch. </span></p><h6><a name="-n951" class="md-header-anchor"></a></h6><h4><a name="avatar-dance-off-what-makes-a-group-to-appear-bonded-and-powerful-harin-lee" class="md-header-anchor"></a><span>Avatar dance off: What makes a group to appear bonded and powerful? (</span><em><span>Harin Lee</span></em><span>)</span></h4><p><span>Previous studies have suggested that the prosocial effects which arise  following synchrony during music and dance may serve as a mechanism for  people to bond socially. However, other research has proposed that  synchrony could be a mechanism for signalling coalition to demonstrate  fitness, which is expressed by a group’s ability to effectively  cooperate. We assessed these two theories by showing participants  virtual avatars engaged in different forms of group dance and then  examining their perceived social closeness and formidability of a group. Participants perceived the groups to be more socially bonded and  formidable when they aligned movement than when they misaligned  movement, with participants perceiving groups moving in unison as the  most bonded and formidable. These findings strengthen the hypothesis  that music and dance may have had an adaptive function in human  evolution.</span></p><h6><a name="-n958" class="md-header-anchor"></a></h6><h4><a name="future-directions-in-music-and-emotion-studies-adopting-a-goal-directed-dimensional-appraisal-account-of-musical-emotions-thomas-lennie" class="md-header-anchor"></a><span>Future directions in music and emotion studies: adopting a goal-directed dimensional-appraisal account of musical emotions (</span><em><span>Thomas Lennie</span></em><span>)</span></h4><p><span>The core-effect model (Russell, 1980) is a staple in music psychology  studies to describe peoples’ emotional interpretations (Juslin &amp;  Sloboda, 2010).  However, recent reviews show that while arousal  performs well across multiple studies and can be linked to several  acoustic cues, valence is considered a more cognitive process that  varies between individuals (Cespedes &amp; Eerola, 2018). This suggests a distinction to be drawn between stimulus-driven and cognitively-driven  (individual) components of emotional experiences to music, that is not  accurately captured by ‘core-affect’ ratings of musical stimuli.  Appraisal theory is well suited to study individual cognitive  evaluations of stimuli and highlights the importance of what makes a  stimulus meaningful and relevant to an individual (Scherer, 2013). In  order to explore individual differences in valence judgements, a  two-part experiment, consisting of an online survey (n = 102) and  follow-up interviews (n = 11), was designed. Its aim was to review  music-specific cognitive evaluations, hypothesised to influence felt  emotional judgments and lead to individual differences in valence  ratings (Scherer, 2013).</span>
<span>Results indicated that several hypothesised  music-specific cognitive evaluations show a significant influence upon  individual ratings of valence and interest across 60 stimuli with high  ecological validity from 5 different genres. The study concludes, along  with recent non-musical studies (Kuppens et al. 2012), that there is a  benefit to incorporating a dimensional-appraisal model of musical  emotions to better understand individual differences in emotional  responses to music. Furthermore, three distinct levels of appraisal  exist: stimulus-driven, goal-driven and meta-appraisal driven that adds  nuanced meaning to contextual factors. It is proposed that future  studies will be aided from adopting a goal-directed approach to  interpreting musical emotions in a given context that allows for the  relevance and meaning of a stimulus to an organism to be highlighted. </span></p><h6><a name="-n971" class="md-header-anchor"></a></h6><h4><a name="reflections-on-chinese-and-british-graded-piano-examination-systems----shcm-and-abrsm-as-case-studies-楚然-罗-churan-luo" class="md-header-anchor"></a><span>Reflections on Chinese and British Graded Piano Examination Systems – SHCM and ABRSM as Case Studies (</span><em><span>楚然 罗 (Churan Luo)</span></em><span>)</span></h4><p><span>The social art examination is an activity to evaluate and guide the  artistic level of art learners through examinations. At present, the  relevant systems in China and Britain are relatively well established.  Although due to various social and historical factors, the development  of the graded music examination system in two countries is different.  Because of space limitations, this article only uses the Piano  Examination of Shanghai Conservatory of Music (SHCM) and Associated  Board of the Royal Schools of Music (ABRSM) as the representatives of  the Chinese and British graded music examination systems. Compare the  existing Chinese and British graded systems with constructions,  syllabuses, exam pieces, existing disputes and so on, try to explore the similarities and differences between the two through objective data  analysis, provide inspiration and reference for the two graded systems,  promote the sustainable development of the piano learners, and cultivate lifelong artistic interests and hobbies.</span></p><h6><a name="-n974" class="md-header-anchor"></a></h6><h4><a name="the-emotive-and-neurological-response-to-break-routines-in-different-music-genres-amelia-s-turrell-amir-homayoun-javadi--andrea-halpern" class="md-header-anchor"></a><span>The Emotive and Neurological Response to Break Routines in Different Music Genres (</span><em><span>Amelia S Turrell, Amir-Homayoun Javadi,  Andrea Halpern</span></em><span>)</span></h4><p><span>Break routines (BR) relate to peak-pleasurable emotions due to tension  in build-ups and fulfilled expectancies in drops. It is unclear whether  emotive and neurological effects are genre dependent. Here, we assessed  EDM BR and analogue BR in classical music using 2-dimensional valence  and arousal space and continuous EEG. There were no differences in brain activity or ratings across the genres, suggesting BR emotions and PFC  activity rely on music structures and are not genre dependent.</span></p><h6><a name="-n979" class="md-header-anchor"></a></h6><h4><a name="an-investigation-into-the-relationship-between-musical-imagery-and-anxiety-michelle-ulor-freya-bailes-daryl-oconnor" class="md-header-anchor"></a><span>An Investigation into the Relationship Between Musical Imagery and Anxiety (</span><em><span>Michelle Ulor, Freya Bailes, Daryl O&#39;Connor</span></em><span>)</span></h4><p><span>Researchers have shown how distressing mental images maintain anxiety  (Hirsch &amp; Holmes, 2007), but also how imagery can be used in  treatment (Felix et al., 2018). Musical imagery and anxiety are common  in everyday life, and psychology has shown that the relationship between anxiety and mental imagery is of interest, yet surprisingly nothing is  known about the natural co-occurrence of the musical imagery experience  and anxiety. A cross-sectional survey primarily investigated the  relationship between anxiety and musical imagery experiences. 432  participants completed pre-existing measures of anxiety (STAI),  depression (CESD), involuntary musical imagery (IMIS), auditory imagery  (BAIS) and thought control (TCQ), combined with newly constructed  questions about sleep. The primary analysis revealed a positive  association between trait anxiety and the frequency of involuntary  musical imagery, providing a clearer understanding of the relationship  between musical imagery and anxiety, which has implications for using  voluntary musical imagery to reduce anxiety. </span></p><h6><a name="-n985" class="md-header-anchor"></a></h6><h4><a name="singers-are-affected-by-the-presence-of-their-own-performances-when-evaluating-their-peers-xinyue-wang-pauline-larrouy-maestri" class="md-header-anchor"></a><span>Singers are affected by the presence of their own performances when evaluating their peers (</span><em><span>Xinyue Wang, Pauline Larrouy-Maestri</span></em><span>)</span></h4><p><span>Listeners appear to effortlessly judge whether performances are sang in- or out-of-tune. However, their judgments can be affected by non-musical factors such as the context of the evaluation. This study explored how  listeners’ judgments of pitch accuracy in operatic performances were  affected by listening to their own singing performances. Specifically,  18 highly trained soprano singers evaluated the performances of 9 peers  through pairwise comparisons, two times: one time with their own  performance included in the set and one time without. Our findings  reveal that one fourth of the participants were strongly affected by the presence of their own performance when evaluating others.  Interestingly, even the consistent listeners slightly changed strategy,  as shown by the different sets of acoustical features predicting the  variance in ratings. Besides identifying a relevant non-musical factor  affecting music performance evaluation, the quantification of such an  effect provides an interesting pedagogical tool to overcome implicit  perceptual biases.</span></p><h6><a name="-n1797" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-7" class="md-header-anchor"></a><span>Paper Session 7</span></h2><h3><a name="music-and-well-being" class="md-header-anchor"></a><span> Music and Well-Being</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n1176" class="md-header-anchor"></a></h6><p><span>11:00-11:20</span></p><h4><a name="psychological-mechanisms-of-participation-in-inclusive-music-projects-experiences-of-marginalised-young-people-maruša-levstek-robin-banerjee" class="md-header-anchor"></a><span>Psychological mechanisms of participation in inclusive music projects: Experiences of marginalised young people (</span><em><span>Maruša Levstek, Robin Banerjee</span></em><span>)</span></h4><p><span>Adopting mixed-methods design, this study explored the psychological  experiences of marginalised young people participating in inclusive  music projects, with attention to inter- and intra-personal outcomes and underlying mechanisms. We worked with four different music projects,  aimed at young people from lower socio-economic backgrounds or those  with special educational needs and/or disabilities. With a total sample  of 134 young people, parents, and creative practitioners, we collected  99 retrospective surveys assessing staff members’ perceptions of changes evident in individual young people, eleven semi-structured focus group  discussions and session notes completed by the staff members after each  session (n = 82). Growth over time in both intra-personal and  inter-personal dimensions was observed, with qualitative data  illuminating possible mechanisms via two themes of ‘Self-Development’  and ‘Social Acknowledgement’. These results are collated in the model of youth empowerment and its relevance to marginalised young people is  highlighted through promotion of active agency and empowerment.</span></p><h6><a name="-n999" class="md-header-anchor"></a></h6><p><span>11:20 - 11:40</span></p><h4><a name="music-listening-as-a-coping-resource-in-domestic-and-international-university-students-dianna-vidas" class="md-header-anchor"></a><span>Music Listening as a Coping Resource in Domestic and International University Students (</span><em><span>Dianna Vidas</span></em><span>)</span></h4><p><span>Adjustment to university is challenging for international students, and existing coping strategies, such as music listening, are rarely examined. This study examined the relationships between student mental health and music use, with a survey of 475 participants (61.9% domestic, 38.1% international students). Music listening was an effective coping strategy for a majority of domestic and international students. Finding music listening an effective coping strategy was related to greater wellbeing for international students. The relationship between motivated music use (emotional, social, and cognitive reasons) and wellbeing differed - for international students, greater wellbeing was associated with more motivated music listening, while the opposite was true for domestic students. For domestic students, more music listening was associated with emotional music listening and lower wellbeing. Students&#39; relationship with music listening as a coping resource is complex, and further research is necessary to directly investigate the effects of music listening on wellbeing.</span></p><h6><a name="-n1802" class="md-header-anchor"></a></h6><hr /><h2><a name="keynote-n2007" class="md-header-anchor"></a><span>Keynote </span></h2><p><span>																							</span><span>(tba) </span></p><p><span>																					</span><span>12:30 - 13:30</span></p><h6><a name="-n2012" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-8" class="md-header-anchor"></a><span>Paper Session 8</span></h2><h3><a name="audience-and-performance" class="md-header-anchor"></a><span>Audience and Performance</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n46" class="md-header-anchor"></a></h6><p><span>14:00-14:20</span></p><h4><a name="empathic-listeners-identify-musically-expressed-emotion-more-accurately-in-improvised-jazz-omer-leshem-michael-schober" class="md-header-anchor"></a><span>Empathic Listeners Identify Musically Expressed Emotion More Accurately in Improvised Jazz (</span><em><span>Omer Leshem, Michael Schober</span></em><span>)</span></h4><p><span>Exploring the generalizability of prior findings that listeners with  greater empathy more accurately identify emotions in pre-selected  classical music excerpts, this study assessed how audience members and  performers feel and think during a live concert with improvised music  and other co-present audience members. A full-length solo concert at a  leading NYC jazz venue was staged to measure reactions of frequent jazz  performance attendees as non-intrusively as possible. The performer was  instructed mid-concert to “perform a 3-5-minute improvised piece with  the intention of conveying sadness.” Audience members (N=23) reported  their perceived and felt emotions. Empathy was assessed using the  Interpersonal Reactivity Index. In Study 2, non-copresent participants  (N=159) listened to a recording of the improvised piece and answered  identical questionnaires. In both studies, cognitive empathy predicted  the likelihood of accurately identifying the expressed emotion.  Surprisingly, affective empathy predicted greater overlap in felt  emotion with the performer only in the online condition.</span></p><h6><a name="-n1008" class="md-header-anchor"></a></h6><p><span>14:20 - 14:40</span></p><h4><a name="there-is-safety-in-numbers-applying-theories-of-social-bonding-to-a-live-western-art-music-concert-audience-katherine-oneill-hauke-egermann" class="md-header-anchor"></a><span>‘There is Safety in Numbers’: Applying theories of social bonding to a live, Western Art Music concert audience (</span><em><span>Katherine O&#39;Neill, Hauke Egermann</span></em><span>)</span></h4><p><span>This study sought to explore whether listeners pay attention to other audience members and if this moderates the emotion induced by the musical performance. A questionnaire was used to measure the collective experience of a concert. Data was collected in three phases at three locations: The Rymer Auditorium, University of York (</span><em><span>n</span></em><span>=49), Sage, Gateshead (</span><em><span>n</span></em><span>=53) and The Sir Jack Lyons Concert Hall, University of York (</span><em><span>n</span></em><span>=112). Information was collected on the typical concert attendance habits of the participants, their emotional response to the music using various accepted measures of emotion, their demographic information and the developing measure of the collective experience of a concert. </span></p><p><span>Semantic exclusion, exploratory and confirmatory factor analysis were run in order to identify the individual factor scores. The resulting measure of the collective experience has five factors based on our analysis: Depth of Processing, Attention, Self-Definition, Solidarity and Satisfaction. These are also supported by the theories of Parasocial Interaction and the In-group Identification.</span></p><h6><a name="-n1807" class="md-header-anchor"></a></h6><hr /><h2><a name="paper-session-9" class="md-header-anchor"></a><span>Paper Session 9</span></h2><h3><a name="togetherness--music-and-prosociality" class="md-header-anchor"></a><span> Togetherness / Music and Prosociality</span></h3><p><span>																				</span><span>Session Chair: tba</span></p><hr /><h6><a name="-n51" class="md-header-anchor"></a></h6><p><span>15:30-15:50 </span></p><h4><a name="music-prosocial-engagement-and-alzheimers-disease-a-scoping-review-and-meta-analysis-aaron-colverson" class="md-header-anchor"></a><span>Music, prosocial engagement, and Alzheimer&#39;s disease: a scoping review and meta-analysis (</span><em><span>Aaron Colverson</span></em><span>)</span></h4><p><span>Music is an area of focus receiving considerable attention for its potential benefits to help manage the effects of neuropsychiatric symptoms upon individuals living with Alzheimer&#39;s disease and related dementias (ADRDs). However, attention is lacking on the potential social value of music to positively influence quality of life for both individuals living with dementias and their caregivers. This scoping review compiles recent reports on this potential, highlighting the social nature of music and its various uses (e.g. listening, making) to affect the often tense and reactive atmosphere surrounding both the individuals living with ADRDs and their caregivers. After screening for eligibility and inclusion, 26 documents were identified, including review articles, experimental studies, recommendations, pilot studies, conference proceedings, book chapters, and executive summaries. Overall, this review concludes that music can facilitate prosocial engagement between persons living with ADRDs and their caregivers, due to a complex interplay of neurobiological mechanisms largely preserved in the ADRDs population. More well designed and well controlled empirical studies are necessary to clarify contexts in which music and its various uses may be helpful to improve quality of life for both the individuals suffering from ADRDs and their caregivers. Such results would provide further evidence-based support for the use of music to strengthen both formal and informal patient-centered care models.</span></p><h6><a name="-n125" class="md-header-anchor"></a></h6><p><span>15:50-16:10 </span></p><h4><a name="the-social-dimensions-of-collaborative-playlist-making-involved-social-processes-and-promoted-prosocial-consequences-ilana-harris-ian-cross" class="md-header-anchor"></a><span>The Social Dimensions of Collaborative Playlist-Making: Involved Social Processes and Promoted Prosocial Consequences (</span><em><span>Ilana Harris, Ian Cross</span></em><span>)</span></h4><p><span>Inclusion of other in self (IOS) is an index of core social processing implicated in prosocial behaviors. It is thought to occur in joint music-making and promote prosocial behaviors even outside of musical contexts. However, its potential in everyday musical behaviors remains unknown. This study investigates collaborative playlist-making as an avenue by which interactive everyday musical engagement may incorporate social processes and promote prosociality. We recruit participants from varied musical and demographic backgrounds and conduct an online experiment that prompts participants to create playlists with either an algorithm or a (fake) partner. Then, participants are assessed via a recognition task and self-report measures. Results show decreased sensitivity for recognition of one’s own song selections among all participants in the fake partner condition, and increased self-reported IOS for younger participants (&lt;25) in the fake partner condition. Thus, perceived collaboration in technologically mediated musical interaction may differentially elicit prosocial tendencies.</span></p><h6><a name="-n1812" class="md-header-anchor"></a></h6><hr /><h2><a name="closing-remarks" class="md-header-anchor"></a><span>Closing Remarks</span></h2></div>
</body>
</html>
